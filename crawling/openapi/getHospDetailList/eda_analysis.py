"""
ë³‘ì› ì „ì²´ì •ë³´ ë°ì´í„° EDA ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
================================================================================
ì‘ì„±ì¼: 2026-01-17
ëª©ì : ë³‘ì›ì „ì²´ì •ë³´_20260116_212603.csv íŒŒì¼ì— ëŒ€í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
================================================================================
"""

import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path

# íŒŒì¼ ê²½ë¡œ
INPUT_FILE = r"d:\git_gb4pro\crawling\openapi\getHospDetailList\data\ë³‘ì›ì „ì²´ì •ë³´_20260116_212603.csv"
OUTPUT_DIR = r"d:\git_gb4pro\crawling\openapi\getHospDetailList\REPORT"

# ì¶œë ¥ íŒŒì¼ëª…
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
OUTPUT_FILE = Path(OUTPUT_DIR) / f"EDA_ë¶„ì„ê²°ê³¼_{timestamp}.md"

print("="*80)
print("ë³‘ì› ì „ì²´ì •ë³´ ë°ì´í„° EDA ë¶„ì„")
print("="*80)
print()

# ============================================================================
# 1. ë°ì´í„° ë¡œë“œ
# ============================================================================
print("[1ë‹¨ê³„] ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
print(f"[ì™„ë£Œ] ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê±´, {len(df.columns)}ê°œ ì»¬ëŸ¼")
print()

# ============================================================================
# 2. ê¸°ë³¸ ì •ë³´ ë¶„ì„
# ============================================================================
print("[2ë‹¨ê³„] ê¸°ë³¸ ì •ë³´ ë¶„ì„ ì¤‘...")

# ë°ì´í„° í¬ê¸°
total_records = len(df)
total_columns = len(df.columns)
memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024

# ì»¬ëŸ¼ ë¶„ë¥˜ (APIë³„)
api_prefixes = {
    'ì›ë³¸': ['ì›ë³¸_'],
    'eqp': ['eqp_'],
    'dtl': ['dtl_'],
    'dgsbjt': ['dgsbjt_'],
    'trnsprt': ['trnsprt_'],
    'medoft': ['medoft_'],
    'foepaddc': ['foepaddc_'],
    'nursiggrd': ['nursiggrd_'],
    'spcldiag': ['spcldiag_'],
    'etchst': ['etchst_']
}

api_column_counts = {}
for api_name, prefixes in api_prefixes.items():
    count = sum(1 for col in df.columns if any(col.startswith(prefix) for prefix in prefixes))
    api_column_counts[api_name] = count

print(f"[ì™„ë£Œ] ê¸°ë³¸ ì •ë³´ ë¶„ì„ ì™„ë£Œ")
print()

# ============================================================================
# 3. ê²°ì¸¡ì¹˜ ë¶„ì„
# ============================================================================
print("[3ë‹¨ê³„] ê²°ì¸¡ì¹˜ ë¶„ì„ ì¤‘...")

# ì „ì²´ ê²°ì¸¡ì¹˜
total_missing = df.isnull().sum().sum()
total_cells = total_records * total_columns
missing_rate = (total_missing / total_cells) * 100

# ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜
missing_by_column = df.isnull().sum()
missing_columns = missing_by_column[missing_by_column > 0].sort_values(ascending=False)

# APIë³„ ê²°ì¸¡ì¹˜
api_missing = {}
for api_name, prefixes in api_prefixes.items():
    api_cols = [col for col in df.columns if any(col.startswith(prefix) for prefix in prefixes)]
    if api_cols:
        api_df = df[api_cols]
        api_total_missing = api_df.isnull().sum().sum()
        api_total_cells = len(api_df) * len(api_cols)
        api_missing_rate = (api_total_missing / api_total_cells) * 100 if api_total_cells > 0 else 0
        api_missing[api_name] = {
            'total_missing': api_total_missing,
            'total_cells': api_total_cells,
            'missing_rate': api_missing_rate
        }

print(f"[ì™„ë£Œ] ê²°ì¸¡ì¹˜ ë¶„ì„ ì™„ë£Œ")
print()

# ============================================================================
# 4. APIë³„ ì‘ë‹µë¥  ë¶„ì„
# ============================================================================
print("[4ë‹¨ê³„] APIë³„ ì‘ë‹µë¥  ë¶„ì„ ì¤‘...")

# ê° APIë³„ë¡œ ìµœì†Œ 1ê°œ ì´ìƒì˜ ê°’ì´ ìˆëŠ” ë ˆì½”ë“œ ìˆ˜ ê³„ì‚°
api_response_rates = {}
for api_name, prefixes in api_prefixes.items():
    if api_name == 'ì›ë³¸':
        continue
    api_cols = [col for col in df.columns if any(col.startswith(prefix) for prefix in prefixes)]
    if api_cols:
        # í•´ë‹¹ APIì˜ ëª¨ë“  ì»¬ëŸ¼ì´ NaNì´ ì•„ë‹Œ ë ˆì½”ë“œ ìˆ˜
        has_data = df[api_cols].notna().any(axis=1).sum()
        response_rate = (has_data / total_records) * 100
        api_response_rates[api_name] = {
            'records_with_data': has_data,
            'response_rate': response_rate
        }

print(f"[ì™„ë£Œ] APIë³„ ì‘ë‹µë¥  ë¶„ì„ ì™„ë£Œ")
print()

# ============================================================================
# 5. ì£¼ìš” ì»¬ëŸ¼ í†µê³„ ë¶„ì„
# ============================================================================
print("[5ë‹¨ê³„] ì£¼ìš” ì»¬ëŸ¼ í†µê³„ ë¶„ì„ ì¤‘...")

# ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
numeric_stats = {}

# ì£¼ìš” ìˆ«ìí˜• ì»¬ëŸ¼ ì„ íƒ
key_numeric_cols = [
    'eqp_stdSickbdCnt',  # ì¼ë°˜ë³‘ìƒìˆ˜
    'eqp_hghrSickbdCnt',  # ìƒê¸‰ë³‘ìƒìˆ˜
    'eqp_emymCnt',  # ì‘ê¸‰ì‹¤ìˆ˜
    'medoft_oftCnt',  # ì˜ë£Œì¥ë¹„ìˆ˜
    'nursiggrd_careGrd',  # ê°„í˜¸ë“±ê¸‰
]

for col in key_numeric_cols:
    if col in df.columns:
        # ìˆ«ìë¡œ ë³€í™˜ ì‹œë„ (ë¬¸ìì—´ì´ ì„ì—¬ ìˆì„ ìˆ˜ ìˆìŒ)
        col_data = pd.to_numeric(df[col], errors='coerce').dropna()
        if len(col_data) > 0:
            numeric_stats[col] = {
                'count': len(col_data),
                'mean': col_data.mean(),
                'std': col_data.std(),
                'min': col_data.min(),
                'max': col_data.max(),
                'median': col_data.median()
            }

print(f"[ì™„ë£Œ] ì£¼ìš” ì»¬ëŸ¼ í†µê³„ ë¶„ì„ ì™„ë£Œ")
print()

# ============================================================================
# 6. ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„
# ============================================================================
print("[6ë‹¨ê³„] ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ ì¤‘...")

# ì£¼ìš” ë²”ì£¼í˜• ì»¬ëŸ¼
key_categorical_cols = [
    'eqp_clCdNm',  # ì¢…ë³„
    'eqp_sidoCdNm',  # ì‹œë„
    'eqp_sgguCdNm',  # ì‹œêµ°êµ¬
]

categorical_stats = {}
for col in key_categorical_cols:
    if col in df.columns:
        value_counts = df[col].value_counts()
        categorical_stats[col] = {
            'unique_count': len(value_counts),
            'top_5': value_counts.head(5).to_dict()
        }

print(f"[ì™„ë£Œ] ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
print()

# ============================================================================
# 7. ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
# ============================================================================
print("[7ë‹¨ê³„] ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

md_content = f"""# ë³‘ì› ì „ì²´ì •ë³´ ë°ì´í„° EDA ë¶„ì„ ë³´ê³ ì„œ

**ë¶„ì„ì¼ì‹œ**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**ë°ì´í„° íŒŒì¼**: `ë³‘ì›ì „ì²´ì •ë³´_20260116_212603.csv`  
**ë¶„ì„ ë„êµ¬**: Python pandas

---

## ğŸ“Š 1. ë°ì´í„° ê°œìš”

### ê¸°ë³¸ ì •ë³´
- **ì´ ë ˆì½”ë“œ ìˆ˜**: {total_records:,}ê±´
- **ì´ ì»¬ëŸ¼ ìˆ˜**: {total_columns}ê°œ
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {memory_usage:.2f} MB
- **ì „ì²´ ê²°ì¸¡ì¹˜**: {total_missing:,}ê°œ ({missing_rate:.2f}%)

### APIë³„ ì»¬ëŸ¼ ìˆ˜

| API | ì»¬ëŸ¼ ìˆ˜ | ì„¤ëª… |
|-----|---------|------|
"""

# APIë³„ ì»¬ëŸ¼ ìˆ˜ í…Œì´ë¸”
api_descriptions = {
    'ì›ë³¸': 'ì›ë³¸ ë°ì´í„° (ê¸°ê´€ì½”ë“œ, ë³‘ì›ëª…, ì£¼ì†Œ)',
    'eqp': 'ì‹œì„¤ì •ë³´ (ë³‘ìƒìˆ˜, ì‘ê¸‰ì‹¤ ë“±)',
    'dtl': 'ì„¸ë¶€ì •ë³´ (ì§„ë£Œì‹œê°„, ì£¼ì°¨ì •ë³´ ë“±)',
    'dgsbjt': 'ì§„ë£Œê³¼ëª©ì •ë³´',
    'trnsprt': 'êµí†µì •ë³´',
    'medoft': 'ì˜ë£Œì¥ë¹„ì •ë³´',
    'foepaddc': 'ì‹ëŒ€ê°€ì‚°ì •ë³´',
    'nursiggrd': 'ê°„í˜¸ë“±ê¸‰ì •ë³´',
    'spcldiag': 'íŠ¹ìˆ˜ì§„ë£Œì •ë³´',
    'etchst': 'ê¸°íƒ€ì¸ë ¥ìˆ˜ì •ë³´'
}

for api_name in ['ì›ë³¸', 'eqp', 'dtl', 'dgsbjt', 'trnsprt', 'medoft', 'foepaddc', 'nursiggrd', 'spcldiag', 'etchst']:
    count = api_column_counts.get(api_name, 0)
    desc = api_descriptions.get(api_name, '')
    md_content += f"| {api_name} | {count} | {desc} |\n"

md_content += """
---

## ğŸ“ˆ 2. APIë³„ ì‘ë‹µë¥  ë¶„ì„

ê° APIë³„ë¡œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ë ˆì½”ë“œì˜ ë¹„ìœ¨ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

| API | ë°ì´í„° ì¡´ì¬ ë ˆì½”ë“œ ìˆ˜ | ì‘ë‹µë¥  |
|-----|---------------------|--------|
"""

for api_name in ['eqp', 'dtl', 'dgsbjt', 'trnsprt', 'medoft', 'foepaddc', 'nursiggrd', 'spcldiag', 'etchst']:
    if api_name in api_response_rates:
        stats = api_response_rates[api_name]
        md_content += f"| {api_name} | {stats['records_with_data']:,}ê±´ | {stats['response_rate']:.1f}% |\n"

md_content += """
### ë¶„ì„ ê²°ê³¼

"""

# ì‘ë‹µë¥  ê¸°ì¤€ ë¶„ë¥˜
high_response = [api for api, stats in api_response_rates.items() if stats['response_rate'] >= 80]
medium_response = [api for api, stats in api_response_rates.items() if 50 <= stats['response_rate'] < 80]
low_response = [api for api, stats in api_response_rates.items() if stats['response_rate'] < 50]

if high_response:
    md_content += f"- **ë†’ì€ ì‘ë‹µë¥  (â‰¥80%)**: {', '.join(high_response)}\n"
if medium_response:
    md_content += f"- **ì¤‘ê°„ ì‘ë‹µë¥  (50-80%)**: {', '.join(medium_response)}\n"
if low_response:
    md_content += f"- **ë‚®ì€ ì‘ë‹µë¥  (<50%)**: {', '.join(low_response)}\n"

md_content += """
---

## ğŸ” 3. ê²°ì¸¡ì¹˜ ë¶„ì„

### APIë³„ ê²°ì¸¡ì¹˜ í˜„í™©

| API | ê²°ì¸¡ì¹˜ ìˆ˜ | ì „ì²´ ì…€ ìˆ˜ | ê²°ì¸¡ë¥  |
|-----|----------|-----------|--------|
"""

for api_name in ['ì›ë³¸', 'eqp', 'dtl', 'dgsbjt', 'trnsprt', 'medoft', 'foepaddc', 'nursiggrd', 'spcldiag', 'etchst']:
    if api_name in api_missing:
        stats = api_missing[api_name]
        md_content += f"| {api_name} | {stats['total_missing']:,} | {stats['total_cells']:,} | {stats['missing_rate']:.1f}% |\n"

md_content += f"""
### ê²°ì¸¡ì¹˜ê°€ ë§ì€ ìƒìœ„ 10ê°œ ì»¬ëŸ¼

| ìˆœìœ„ | ì»¬ëŸ¼ëª… | ê²°ì¸¡ì¹˜ ìˆ˜ | ê²°ì¸¡ë¥  |
|------|--------|----------|--------|
"""

for idx, (col, count) in enumerate(missing_columns.head(10).items(), 1):
    missing_pct = (count / total_records) * 100
    md_content += f"| {idx} | `{col}` | {count:,} | {missing_pct:.1f}% |\n"

md_content += """
---

## ğŸ“Š 4. ì£¼ìš” ì»¬ëŸ¼ í†µê³„ ë¶„ì„

### ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„

"""

for col, stats in numeric_stats.items():
    md_content += f"""
#### {col}

| í†µê³„ëŸ‰ | ê°’ |
|--------|-----|
| ë°ì´í„° ìˆ˜ | {stats['count']:,} |
| í‰ê·  | {stats['mean']:.2f} |
| í‘œì¤€í¸ì°¨ | {stats['std']:.2f} |
| ìµœì†Ÿê°’ | {stats['min']:.2f} |
| ì¤‘ì•™ê°’ | {stats['median']:.2f} |
| ìµœëŒ“ê°’ | {stats['max']:.2f} |

"""

md_content += """
---

## ğŸ“‹ 5. ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„

"""

for col, stats in categorical_stats.items():
    md_content += f"""
### {col}

- **ê³ ìœ ê°’ ìˆ˜**: {stats['unique_count']}ê°œ

**ìƒìœ„ 5ê°œ ê°’**:

| ìˆœìœ„ | ê°’ | ê±´ìˆ˜ |
|------|-----|------|
"""
    for idx, (value, count) in enumerate(stats['top_5'].items(), 1):
        md_content += f"| {idx} | {value} | {count:,} |\n"
    
    md_content += "\n"

md_content += """
---

## ğŸ’¡ 6. ì£¼ìš” ë°œê²¬ì‚¬í•­ ë° ê¶Œì¥ì‚¬í•­

### ì£¼ìš” ë°œê²¬ì‚¬í•­

"""

# ìë™ ë°œê²¬ì‚¬í•­ ìƒì„±
findings = []

# 1. ì‘ë‹µë¥  ê´€ë ¨
if low_response:
    findings.append(f"1. **ë‚®ì€ ì‘ë‹µë¥  API**: {', '.join(low_response)} APIëŠ” ì‘ë‹µë¥ ì´ 50% ë¯¸ë§Œì…ë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ” ë³‘ì›ì´ ë§ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")

# 2. ê²°ì¸¡ì¹˜ ê´€ë ¨
high_missing_cols = [col for col, count in missing_columns.items() if (count / total_records) > 0.5]
if high_missing_cols:
    findings.append(f"2. **ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼**: {len(high_missing_cols)}ê°œ ì»¬ëŸ¼ì´ 50% ì´ìƒì˜ ê²°ì¸¡ë¥ ì„ ë³´ì…ë‹ˆë‹¤.")

# 3. ë°ì´í„° í’ˆì§ˆ
if missing_rate < 30:
    findings.append(f"3. **ì „ì²´ ë°ì´í„° í’ˆì§ˆ**: ì „ì²´ ê²°ì¸¡ë¥ ì´ {missing_rate:.1f}%ë¡œ ì–‘í˜¸í•œ í¸ì…ë‹ˆë‹¤.")
elif missing_rate > 50:
    findings.append(f"3. **ì „ì²´ ë°ì´í„° í’ˆì§ˆ**: ì „ì²´ ê²°ì¸¡ë¥ ì´ {missing_rate:.1f}%ë¡œ ë†’ì€ í¸ì…ë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ ê³¼ì •ì„ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.")

for idx, finding in enumerate(findings, 1):
    md_content += f"{finding}\n\n"

md_content += """
### ê¶Œì¥ì‚¬í•­

1. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: ë¶„ì„ ëª©ì ì— ë”°ë¼ ê²°ì¸¡ì¹˜ê°€ ë§ì€ ì»¬ëŸ¼ì€ ì œì™¸í•˜ê±°ë‚˜ ëŒ€ì²´ê°’ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.
2. **API ì‘ë‹µë¥  ê°œì„ **: ì‘ë‹µë¥ ì´ ë‚®ì€ APIì˜ ê²½ìš°, í•´ë‹¹ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë³‘ì›ë§Œ ëŒ€ìƒìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ê²ƒì´ ì ì ˆí•©ë‹ˆë‹¤.
3. **ë°ì´í„° ê²€ì¦**: ìˆ«ìí˜• ë°ì´í„°ì˜ ì´ìƒì¹˜(outlier)ë¥¼ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ì œê±°í•˜ì„¸ìš”.
4. **ì¶”ê°€ ë¶„ì„**: ì§€ì—­ë³„, ì¢…ë³„ë³„ ë¶„ì„ì„ í†µí•´ ë” ê¹Šì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“ ë¶€ë¡: ì „ì²´ ì»¬ëŸ¼ ëª©ë¡

<details>
<summary>ì „ì²´ {total_columns}ê°œ ì»¬ëŸ¼ ë³´ê¸° (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)</summary>

"""

for idx, col in enumerate(df.columns, 1):
    md_content += f"{idx}. `{col}`\n"

md_content += """
</details>

---

**ë³´ê³ ì„œ ìƒì„±ì¼ì‹œ**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**ë¶„ì„ ë„êµ¬**: Python pandas  
**ë°ì´í„° íŒŒì¼**: `ë³‘ì›ì „ì²´ì •ë³´_20260116_212603.csv`
"""

# íŒŒì¼ ì €ì¥
Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
    f.write(md_content)

print(f"[ì™„ë£Œ] ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
print(f"  ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE}")
print()

print("="*80)
print("EDA ë¶„ì„ ì™„ë£Œ!")
print("="*80)
print()
print(f"ë³´ê³ ì„œ íŒŒì¼: {OUTPUT_FILE}")
