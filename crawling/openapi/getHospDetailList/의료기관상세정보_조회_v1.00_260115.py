"""
ì˜ë£Œê¸°ê´€ë³„ìƒì„¸ì •ë³´ ì¡°íšŒ API í˜¸ì¶œ ìŠ¤í¬ë¦½íŠ¸
================================================================================
ì‘ì„±ì¼: 2026-01-15
ëª©ì : ê±´ê°•ë³´í—˜ì‹¬ì‚¬í‰ê°€ì› ì˜ë£Œê¸°ê´€ë³„ìƒì„¸ì •ë³´ì„œë¹„ìŠ¤ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ì› ìƒì„¸ì •ë³´ ì¡°íšŒ
ì…ë ¥: ë³‘ì›ê¸°ë³¸ëª©ë¡ Excel íŒŒì¼ (ì•”í˜¸í™”ëœ ìš”ì–‘ê¸°í˜¸ í¬í•¨)
ì¶œë ¥: ë³‘ì› ìƒì„¸ì •ë³´ Excel íŒŒì¼
================================================================================
"""

import requests
import json
from typing import Dict, List, Optional
import pandas as pd
from datetime import datetime
import time
import os
from pathlib import Path
from urllib.parse import quote

# ============================================================================
# ì„¤ì • (Configuration)
# ============================================================================

# API ê¸°ë³¸ ì •ë³´
# ì°¸ê³ : ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ API ìƒì„¸ ëª…ì„¸ë¥¼ í™•ì¸í•˜ì—¬ ì •í™•í•œ operation ì´ë¦„ì„ ì„¤ì •í•˜ì„¸ìš”
# ì¼ë°˜ì ì¸ íŒ¨í„´: /getDtlInfo, /getMadmDtlInfo ë“±
API_BASE_URL = "http://apis.data.go.kr/B551182/MadmDtlInfoService2.7/getDtlInfo2.7"

# ì¸ì¦í‚¤ ì„¤ì • (ì—¬ê¸°ì— ë°œê¸‰ë°›ì€ ì¸ì¦í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”)
# ì£¼ì˜: ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ ë³µì‚¬í•œ ë””ì½”ë”© í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
SERVICE_KEY = "Bk8LikYxwbpxf1OKF0mYYonK9RNmYo/mmgtNsZ41rRNxMuIh5s7RgflEXp+Xwp3R0FDR2j01gx62Hc++Jzc2pw=="

# API í‚¤ íƒ€ì… ì„¤ì • (True: ì¸ì½”ë”© í‚¤, False: ë””ì½”ë”© í‚¤)
USE_ENCODED_KEY = False

# ì¬ì‹œë„ ì„¤ì •
MAX_RETRIES = 3          # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 1          # ì´ˆê¸° ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# íƒ€ì„ì•„ì›ƒ ì„¤ì •
CONNECT_TIMEOUT = 10     # ì—°ê²° íƒ€ì„ì•„ì›ƒ (ì´ˆ)
READ_TIMEOUT = 60        # ì½ê¸° íƒ€ì„ì•„ì›ƒ (ì´ˆ)

# ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
ENABLE_CHECKPOINT = True # ì§„í–‰ìƒí™© ì €ì¥ í™œì„±í™”
CHECKPOINT_INTERVAL = 5  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê°„ê²© (ê±´ìˆ˜ ë‹¨ìœ„)

# ì…ë ¥ íŒŒì¼ ì„¤ì •
# ê¸°ë³¸ ì…ë ¥ íŒŒì¼ ê²½ë¡œ (getHospBasisList APIë¡œ ìƒì„±ëœ CSV íŒŒì¼)
INPUT_CSV_FILE = r"D:\git_gb4pro\crawling\openapi\getHospDetailList\data\ì„œìš¸_ê°•ë‚¨êµ¬_í”¼ë¶€ê³¼_20260115_212757.csv"
YKIHO_COLUMN = None  # CSV íŒŒì¼ì—ì„œ ìš”ì–‘ê¸°í˜¸ê°€ ì €ì¥ëœ ì»¬ëŸ¼ëª… (ìë™ íƒì§€)

# ============================================================================
# API í˜¸ì¶œ í•¨ìˆ˜
# ============================================================================

def get_hospital_detail(
    service_key: str,
    use_encoded_key: bool = False,
    ykiho: str = None,
    max_retries: int = MAX_RETRIES,
    retry_delay: int = RETRY_DELAY
) -> Dict:
    """
    ë³‘ì› ìƒì„¸ì •ë³´ API í˜¸ì¶œ í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    
    Parameters:
    -----------
    service_key : str
        ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ ë°œê¸‰ë°›ì€ ì¸ì¦í‚¤ (ì¸ì½”ë”© ë˜ëŠ” ë””ì½”ë”©)
    use_encoded_key : bool
        True: ì¸ì½”ë”© í‚¤ ì‚¬ìš© (URLì— ì§ì ‘ í¬í•¨)
        False: ë””ì½”ë”© í‚¤ ì‚¬ìš© (paramsë¡œ ì „ë‹¬)
    ykiho : str
        ì•”í˜¸í™”ëœ ìš”ì–‘ê¸°í˜¸
    max_retries : int
        ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3)
    retry_delay : int
        ì´ˆê¸° ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ (ê¸°ë³¸ê°’: 1ì´ˆ)
    
    Returns:
    --------
    dict
        API ì‘ë‹µ ë°ì´í„° (JSON í˜•ì‹)
    
    Raises:
    -------
    Exception
        API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
    """
    
    # ìš”ì²­ íŒŒë¼ë¯¸í„° êµ¬ì„±
    params = {
        'ykiho': ykiho,      # ì•”í˜¸í™”ëœ ìš”ì–‘ê¸°í˜¸
        '_type': 'json'      # JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°
    }
    
    # API í‚¤ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    if use_encoded_key:
        # ì¸ì½”ë”© í‚¤: URLì— ì§ì ‘ í¬í•¨ (íŠ¹ìˆ˜ë¬¸ì URL ì¸ì½”ë”© í•„ìš”)
        encoded_key = quote(service_key, safe='')
        api_url = f"{API_BASE_URL}?ServiceKey={encoded_key}"
    else:
        # ë””ì½”ë”© í‚¤: paramsë¡œ ì „ë‹¬ (requestsê°€ ìë™ ì¸ì½”ë”©)
        api_url = API_BASE_URL
        params['ServiceKey'] = service_key
    
    # ì¬ì‹œë„ ë¡œì§
    last_exception = None
    for attempt in range(max_retries + 1):
        try:
            if attempt > 0:
                wait_time = retry_delay * (2 ** (attempt - 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                print(f"[ì¬ì‹œë„ {attempt}/{max_retries}] {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(wait_time)
            
            # API í˜¸ì¶œ
            response = requests.get(
                api_url, 
                params=params, 
                timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)
            )
            
            # HTTP ìƒíƒœ ì½”ë“œ í™•ì¸
            response.raise_for_status()
            
            # JSON íŒŒì‹±
            data = response.json()
            
            # API ì‘ë‹µ í—¤ë” í™•ì¸
            header = data['response']['header']
            if header['resultCode'] != '00':
                raise Exception(f"API ì˜¤ë¥˜ [{header['resultCode']}]: {header['resultMsg']}")
            
            return data
            
        except requests.exceptions.Timeout as e:
            last_exception = Exception(f"API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ (ì—°ê²°: {CONNECT_TIMEOUT}ì´ˆ, ì½ê¸°: {READ_TIMEOUT}ì´ˆ)")
            if attempt < max_retries:
                print(f"[ê²½ê³ ] {last_exception}")
                continue
        except requests.exceptions.ConnectionError as e:
            last_exception = Exception("ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            if attempt < max_retries:
                print(f"[ê²½ê³ ] {last_exception}")
                continue
        except requests.exceptions.HTTPError as e:
            # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì‘ë‹µ ë‚´ìš© ì¶œë ¥
            error_msg = f"HTTP ì˜¤ë¥˜: {e}"
            try:
                error_response = e.response.text
                print(f"\n[API ì‘ë‹µ ë‚´ìš©]\n{error_response}\n")
                error_msg += f"\nì‘ë‹µ ë‚´ìš©: {error_response}"
            except:
                pass
            last_exception = Exception(error_msg)
            # HTTP ì—ëŸ¬ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ (ì¸ì¦ ì˜¤ë¥˜ ë“±)
            break
        except KeyError as e:
            last_exception = Exception(f"ì‘ë‹µ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜: {e}")
            break
        except Exception as e:
            last_exception = Exception(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            if attempt < max_retries:
                print(f"[ê²½ê³ ] {last_exception}")
                continue
    
    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
    raise last_exception


def save_checkpoint(data: Dict, checkpoint_file: str):
    """
    ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    
    Parameters:
    -----------
    data : dict
        ì €ì¥í•  ë°ì´í„°
    checkpoint_file : str
        ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
    """
    try:
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"[ì²´í¬í¬ì¸íŠ¸ ì €ì¥] {checkpoint_file}")
    except Exception as e:
        print(f"[ê²½ê³ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")


def load_checkpoint(checkpoint_file: str) -> Optional[Dict]:
    """
    ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    
    Parameters:
    -----------
    checkpoint_file : str
        ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
    
    Returns:
    --------
    dict or None
        ì €ì¥ëœ ë°ì´í„° ë˜ëŠ” None
    """
    if not os.path.exists(checkpoint_file):
        return None
    
    try:
        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"[ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ] {checkpoint_file}")
        print(f"  - ì´ì „ ì§„í–‰: {data.get('processed_count', 0)}ê±´ ì²˜ë¦¬ ì™„ë£Œ")
        return data
    except Exception as e:
        print(f"[ê²½ê³ ] ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_hospital_list_from_csv(filename: str, ykiho_column: str = None) -> pd.DataFrame:
    """
    CSV íŒŒì¼ì—ì„œ ë³‘ì› ëª©ë¡ ì½ê¸°
    
    Parameters:
    -----------
    filename : str
        CSV íŒŒì¼ ê²½ë¡œ
    ykiho_column : str, optional
        ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ëª… (Noneì´ë©´ ìë™ íƒì§€)
    
    Returns:
    --------
    pd.DataFrame
        ë³‘ì› ëª©ë¡ ë°ì´í„°í”„ë ˆì„
    """
    print(f"[CSV ì½ê¸°] {filename}")
    # Windowsì—ì„œ Excelë¡œ ì €ì¥í•œ CSVëŠ” ë³´í†µ cp949 ì¸ì½”ë”©
    # ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ì‹œë„í•˜ì—¬ ì½ê¸°
    encodings = ['cp949', 'utf-8-sig', 'utf-8', 'euc-kr']
    df = None
    last_error = None
    
    for encoding in encodings:
        try:
            df = pd.read_csv(filename, encoding=encoding)
            print(f"  - ì¸ì½”ë”©: {encoding} (ì„±ê³µ)")
            break
        except (UnicodeDecodeError, Exception) as e:
            last_error = e
            continue
    
    if df is None:
        raise Exception(f"CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
    
    print(f"  - ì´ {len(df)}ê±´")
    print(f"  - ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
    
    # ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ ìë™ íƒì§€
    if ykiho_column is None:
        possible_columns = ['ykiho', 'ì•”í˜¸í™”ìš”ì–‘ê¸°í˜¸', 'ìš”ì–‘ê¸°í˜¸', 'YKIHO', 'ykiho_enc']
        for col in possible_columns:
            if col in df.columns:
                ykiho_column = col
                print(f"  - ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ ìë™ íƒì§€: {ykiho_column}")
                break
        
        if ykiho_column is None:
            # CSV íŒŒì¼ì˜ ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ë³‘ì›ëª…ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ ë§ˆì§€ë§‰ ì»¬ëŸ¼ í™•ì¸
            print(f"  [ê²½ê³ ] ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"  ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
            raise Exception(f"ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
    
    # ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    if ykiho_column not in df.columns:
        raise Exception(f"ì»¬ëŸ¼ '{ykiho_column}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
    
    return df, ykiho_column  # DataFrameê³¼ ì»¬ëŸ¼ëª…ì„ í•¨ê»˜ ë°˜í™˜


def get_all_hospital_details(
    service_key: str,
    use_encoded_key: bool = False,
    hospital_df: pd.DataFrame = None,
    ykiho_column: str = 'ykiho',
    max_results: Optional[int] = None,
    enable_checkpoint: bool = ENABLE_CHECKPOINT,
    checkpoint_file: Optional[str] = None
) -> List[Dict]:
    """
    ëª¨ë“  ë³‘ì›ì˜ ìƒì„¸ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì²´í¬í¬ì¸íŠ¸ ì§€ì›)
    
    Parameters:
    -----------
    service_key : str
        ê³µê³µë°ì´í„°í¬í„¸ì—ì„œ ë°œê¸‰ë°›ì€ ì¸ì¦í‚¤
    use_encoded_key : bool
        True: ì¸ì½”ë”© í‚¤ ì‚¬ìš©, False: ë””ì½”ë”© í‚¤ ì‚¬ìš©
    hospital_df : pd.DataFrame
        ë³‘ì› ëª©ë¡ ë°ì´í„°í”„ë ˆì„
    ykiho_column : str
        ìš”ì–‘ê¸°í˜¸ ì»¬ëŸ¼ëª…
    max_results : int, optional
        ìµœëŒ€ ê²°ê³¼ ìˆ˜ (Noneì´ë©´ ì „ì²´ ì¡°íšŒ)
    enable_checkpoint : bool
        ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
    checkpoint_file : str, optional
        ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
    
    Returns:
    --------
    list
        ëª¨ë“  ë³‘ì› ìƒì„¸ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì„¤ì •
    if enable_checkpoint and checkpoint_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_file = f"checkpoint_detail_{timestamp}.json"
    
    # ì´ì „ ì§„í–‰ìƒí™© ë¡œë“œ
    all_items = []
    processed_indices = set()
    start_index = 0
    success_count = 0  # ì„±ê³µ ê±´ìˆ˜ ì¶”ê°€
    
    if enable_checkpoint and checkpoint_file:
        checkpoint_data = load_checkpoint(checkpoint_file)
        if checkpoint_data:
            all_items = checkpoint_data.get('items', [])
            processed_indices = set(checkpoint_data.get('processed_indices', []))
            start_index = checkpoint_data.get('last_index', 0) + 1
            success_count = checkpoint_data.get('success_count', len(all_items))
            print(f"[ì¬ê°œ] ì¸ë±ìŠ¤ {start_index}ë¶€í„° ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            print(f"  - ì´ì „ ì„±ê³µ: {success_count}ê±´")
    
    total_count = len(hospital_df)
    if max_results:
        total_count = min(total_count, max_results)
    
    start_time = time.time()
    
    try:
        for idx in range(start_index, total_count):
            # ì´ë¯¸ ì²˜ë¦¬ëœ ì¸ë±ìŠ¤ëŠ” ê±´ë„ˆë›°ê¸°
            if idx in processed_indices:
                continue
            
            row = hospital_df.iloc[idx]
            ykiho = row[ykiho_column]
            
            # ìš”ì–‘ê¸°í˜¸ ìœ íš¨ì„± í™•ì¸
            if pd.isna(ykiho) or str(ykiho).strip() == '':
                print(f"[ê²½ê³ ] ì¸ë±ìŠ¤ {idx}: ìš”ì–‘ê¸°í˜¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                processed_indices.add(idx)
                continue
            
            # ì§„í–‰ë¥  ê³„ì‚°
            processed_count = len(processed_indices)
            fail_count = processed_count - success_count
            progress_pct = (processed_count / total_count * 100) if total_count > 0 else 0
            elapsed_time = time.time() - start_time
            
            if processed_count > 0 and elapsed_time > 0:
                items_per_sec = processed_count / elapsed_time
                remaining_items = total_count - processed_count
                eta_seconds = remaining_items / items_per_sec if items_per_sec > 0 else 0
                eta_str = f", ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {int(eta_seconds)}ì´ˆ"
            else:
                eta_str = ""
            
            print(f"[ì§„í–‰] {processed_count}/{total_count}ê±´ ({progress_pct:.1f}%) - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {fail_count}{eta_str}")
            print(f"  - ì¸ë±ìŠ¤ {idx}: {row.get('yadmNm', 'ì•Œ ìˆ˜ ì—†ìŒ')} (ìš”ì–‘ê¸°í˜¸: {ykiho[:20]}...)")
            
            # API í˜¸ì¶œ
            try:
                data = get_hospital_detail(
                    service_key=service_key,
                    use_encoded_key=use_encoded_key,
                    ykiho=ykiho
                )
                
                # ì‘ë‹µ ë°”ë”” í™•ì¸
                body = data['response']['body']
                items = body.get('items', {})
                
                # itemsê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                if not items or isinstance(items, str):
                    print(f"  [X] ìƒì„¸ì •ë³´ ì—†ìŒ")
                    processed_indices.add(idx)
                    continue
                
                # item ì¶”ì¶œ
                item_data = items.get('item', {})
                
                # itemì´ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                if not item_data or isinstance(item_data, str):
                    print(f"  [X] ìƒì„¸ì •ë³´ ì—†ìŒ")
                    processed_indices.add(idx)
                    continue
                
                # ë‹¨ì¼ ê²°ê³¼ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if isinstance(item_data, dict):
                    item_data = [item_data]
                
                # ì›ë³¸ ë°ì´í„°ì™€ ë³‘í•©
                for item in item_data:
                    if isinstance(item, dict):
                        # ì›ë³¸ í–‰ì˜ ë°ì´í„° ì¶”ê°€ (í•œê¸€/ì˜ë¬¸ ì»¬ëŸ¼ëª… ëª¨ë‘ ì§€ì›)
                        item['ì›ë³¸_ê¸°ê´€ì½”ë“œ'] = ykiho
                        # ë³‘ì›ëª…: í•œê¸€ ì»¬ëŸ¼ëª… ìš°ì„ , ì—†ìœ¼ë©´ ì˜ë¬¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
                        item['ì›ë³¸_ë³‘ì›ëª…'] = row.get('ë³‘ì›ëª…', row.get('yadmNm', ''))
                        # ì£¼ì†Œ: í•œê¸€ ì»¬ëŸ¼ëª… ìš°ì„ , ì—†ìœ¼ë©´ ì˜ë¬¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
                        item['ì›ë³¸_ì£¼ì†Œ'] = row.get('ì£¼ì†Œ', row.get('addr', ''))
                        all_items.append(item)
                
                success_count += 1
                print(f"  [O] ì¡°íšŒ ì„±ê³µ")
                processed_indices.add(idx)
                
            except Exception as e:
                print(f"  [X] ì˜¤ë¥˜ ë°œìƒ: {e}")
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ê³„ì† ì§„í–‰
                processed_indices.add(idx)
                continue
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ì¼ì • ê°„ê²©ë§ˆë‹¤)
            if enable_checkpoint and checkpoint_file and len(processed_indices) % CHECKPOINT_INTERVAL == 0:
                checkpoint_data = {
                    'last_index': idx,
                    'processed_count': len(processed_indices),
                    'success_count': success_count,
                    'processed_indices': list(processed_indices),
                    'total_count': total_count,
                    'timestamp': datetime.now().isoformat(),
                    'items': all_items
                }
                save_checkpoint(checkpoint_data, checkpoint_file)
            
            # API í˜¸ì¶œ ê°„ê²© (ì´ˆë‹¹ ìš”ì²­ ì œí•œ ê³ ë ¤)
            time.sleep(0.1)
        
        print(f"\n[ì™„ë£Œ] ì´ ì²˜ë¦¬: {processed_count}ê±´ / ì„±ê³µ: {success_count}ê±´ / ì‹¤íŒ¨: {processed_count - success_count}ê±´")
        
        # ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì‚­ì œ
        if enable_checkpoint and checkpoint_file and os.path.exists(checkpoint_file):
            try:
                os.remove(checkpoint_file)
                print(f"[ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ] {checkpoint_file}")
            except:
                pass
        
        return all_items
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ í˜„ì¬ê¹Œì§€ì˜ ë°ì´í„° ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if enable_checkpoint and checkpoint_file:
            checkpoint_data = {
                'last_index': idx if 'idx' in locals() else 0,
                'processed_count': len(processed_indices),
                'processed_indices': list(processed_indices),
                'total_count': total_count,
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'items': all_items
            }
            save_checkpoint(checkpoint_data, checkpoint_file)
            print(f"\n[ì˜¤ë¥˜] ì§„í–‰ìƒí™©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ ì§„í–‰ë©ë‹ˆë‹¤.")
        raise


# ============================================================================
# ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================================

def generate_metadata_markdown(df: pd.DataFrame, csv_filename: str):
    """
    CSV íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
    
    Parameters:
    -----------
    df : pd.DataFrame
        ì €ì¥ëœ ë°ì´í„°í”„ë ˆì„
    csv_filename : str
        CSV íŒŒì¼ ê²½ë¡œ
    """
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ëª… ìƒì„±
    md_filename = csv_filename.replace('.csv', '.md')
    
    # ì»¬ëŸ¼ ì„¤ëª… ë§¤í•‘ (í•œê¸€)
    column_descriptions = {
        'ì›ë³¸_ê¸°ê´€ì½”ë“œ': 'ì…ë ¥ íŒŒì¼ì˜ ì•”í˜¸í™”ëœ ìš”ì–‘ê¸°í˜¸',
        'ì›ë³¸_ë³‘ì›ëª…': 'ì…ë ¥ íŒŒì¼ì˜ ë³‘ì›ëª…',
        'ì›ë³¸_ì£¼ì†Œ': 'ì…ë ¥ íŒŒì¼ì˜ ë³‘ì› ì£¼ì†Œ',
        'yadmNm': 'API ì‘ë‹µ ë³‘ì›ëª…',
        'addr': 'API ì‘ë‹µ ì£¼ì†Œ',
        'telno': 'ì „í™”ë²ˆí˜¸',
        'hospUrl': 'ë³‘ì› í™ˆí˜ì´ì§€ URL',
        'clCdNm': 'ì¢…ë³„ì½”ë“œëª…',
        'sidoCdNm': 'ì‹œë„ì½”ë“œëª…',
        'sgguCdNm': 'ì‹œêµ°êµ¬ì½”ë“œëª…',
        'emdongNm': 'ìë©´ë™ëª…',
        'postNo': 'ìš°í¸ë²ˆí˜¸',
        'XPos': 'Xì¢Œí‘œ(ê²½ë„)',
        'YPos': 'Yì¢Œí‘œ(ìœ„ë„)',
        'emyDayTelNo1': 'ì‘ê¸‰ì‹¤ ì£¼ê°„ ì „í™”ë²ˆí˜¸1',
        'emyDayTelNo2': 'ì‘ê¸‰ì‹¤ ì£¼ê°„ ì „í™”ë²ˆí˜¸2',
        'emyDayYn': 'ì‘ê¸‰ì‹¤ ì£¼ê°„ ìš´ì˜ ì—¬ë¶€',
        'emyNgtTelNo1': 'ì‘ê¸‰ì‹¤ ì•¼ê°„ ì „í™”ë²ˆí˜¸1',
        'emyNgtTelNo2': 'ì‘ê¸‰ì‹¤ ì•¼ê°„ ì „í™”ë²ˆí˜¸2',
        'emyNgtYn': 'ì‘ê¸‰ì‹¤ ì•¼ê°„ ìš´ì˜ ì—¬ë¶€',
        'lunchWeek': 'í‰ì¼ ì ì‹¬ì‹œê°„',
        'lunchSat': 'í† ìš”ì¼ ì ì‹¬ì‹œê°„',
        'noTrmtHoli': 'ê³µíœ´ì¼ ì§„ë£Œ ì—¬ë¶€',
        'noTrmtSun': 'ì¼ìš”ì¼ ì§„ë£Œ ì—¬ë¶€',
        'parkEtc': 'ì£¼ì°¨ ì•ˆë‚´',
        'parkQty': 'ì£¼ì°¨ ê°€ëŠ¥ ëŒ€ìˆ˜',
        'parkXpnsYn': 'ì£¼ì°¨ë¹„ ìœ ë¬´',
        'plcDir': 'ëŒ€ì¤‘êµí†µ ì´ìš© ë°©í–¥',
        'plcDist': 'ëŒ€ì¤‘êµí†µ ì´ìš© ê±°ë¦¬',
        'plcNm': 'ëŒ€ì¤‘êµí†µ ì´ìš© ì¥ì†Œëª…',
        'rcvSat': 'í† ìš”ì¼ ì ‘ìˆ˜ì‹œê°„',
        'rcvWeek': 'í‰ì¼ ì ‘ìˆ˜ì‹œê°„',
        'trmtMonStart': 'ì›”ìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtMonEnd': 'ì›”ìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„',
        'trmtTueStart': 'í™”ìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtTueEnd': 'í™”ìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„',
        'trmtWedStart': 'ìˆ˜ìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtWedEnd': 'ìˆ˜ìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„',
        'trmtThuStart': 'ëª©ìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtThuEnd': 'ëª©ìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„',
        'trmtFriStart': 'ê¸ˆìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtFriEnd': 'ê¸ˆìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„',
        'trmtSatStart': 'í† ìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtSatEnd': 'í† ìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„',
        'trmtSunStart': 'ì¼ìš”ì¼ ì§„ë£Œ ì‹œì‘ì‹œê°„',
        'trmtSunEnd': 'ì¼ìš”ì¼ ì§„ë£Œ ì¢…ë£Œì‹œê°„'
    }
    
    with open(md_filename, 'w', encoding='utf-8') as f:
        # ì œëª©
        f.write(f"# ë³‘ì› ìƒì„¸ì •ë³´ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ\n\n")
        f.write(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**ë°ì´í„° íŒŒì¼**: `{Path(csv_filename).name}`\n\n")
        
        # ê¸°ë³¸ ì •ë³´
        f.write("## ğŸ“Š ë°ì´í„° ê°œìš”\n\n")
        f.write(f"- **ì´ ë ˆì½”ë“œ ìˆ˜**: {len(df):,}ê±´\n")
        f.write(f"- **ì´ ì»¬ëŸ¼ ìˆ˜**: {len(df.columns)}ê°œ\n\n")
        
        # ì»¬ëŸ¼ ì„¤ëª…
        f.write("## ğŸ“‹ ì»¬ëŸ¼ ì„¤ëª…\n\n")
        f.write("| ì»¬ëŸ¼ëª… | ì„¤ëª… | ë°ì´í„° íƒ€ì… |\n")
        f.write("|--------|------|------------|\n")
        for col in df.columns:
            desc = column_descriptions.get(col, '(ì„¤ëª… ì—†ìŒ)')
            dtype = str(df[col].dtype)
            f.write(f"| `{col}` | {desc} | {dtype} |\n")
        
        # ê¸°ìˆ í†µê³„ - ìˆ«ìí˜• ì»¬ëŸ¼
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_cols) > 0:
            f.write("\n## ğŸ“ˆ ìˆ«ìí˜• ì»¬ëŸ¼ ê¸°ìˆ í†µê³„\n\n")
            stats_df = df[numeric_cols].describe()
            f.write(stats_df.to_markdown())
            f.write("\n\n")
        
        # ê²°ì¸¡ì¹˜ ë¶„ì„
        f.write("## ğŸ” ê²°ì¸¡ì¹˜ ë¶„ì„\n\n")
        missing_data = df.isnull().sum()
        missing_pct = (missing_data / len(df) * 100).round(2)
        missing_df = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': missing_data.index,
            'ê²°ì¸¡ì¹˜ ìˆ˜': missing_data.values,
            'ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)': missing_pct.values
        })
        missing_df = missing_df[missing_df['ê²°ì¸¡ì¹˜ ìˆ˜'] > 0].sort_values('ê²°ì¸¡ì¹˜ ìˆ˜', ascending=False)
        
        if len(missing_df) > 0:
            f.write(missing_df.to_markdown(index=False))
            f.write("\n\n")
        else:
            f.write("ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n")
        
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¶„ì„ (ìƒìœ„ í•­ëª©ë§Œ)
        text_cols = df.select_dtypes(include=['object']).columns
        important_text_cols = [col for col in ['ì›ë³¸_ë³‘ì›ëª…', 'yadmNm', 'clCdNm', 'sidoCdNm', 'sgguCdNm'] if col in text_cols]
        
        if len(important_text_cols) > 0:
            f.write("## ğŸ“ ì£¼ìš” í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¶„í¬\n\n")
            for col in important_text_cols:
                value_counts = df[col].value_counts().head(10)
                if len(value_counts) > 0:
                    f.write(f"### {col}\n\n")
                    f.write(f"- **ê³ ìœ ê°’ ìˆ˜**: {df[col].nunique()}ê°œ\n")
                    f.write(f"- **ìƒìœ„ 10ê°œ ê°’**:\n\n")
                    for idx, (val, count) in enumerate(value_counts.items(), 1):
                        pct = (count / len(df) * 100)
                        val_str = str(val)[:50] + '...' if len(str(val)) > 50 else str(val)
                        f.write(f"  {idx}. `{val_str}`: {count}ê±´ ({pct:.1f}%)\n")
                    f.write("\n")
    
    print(f"[ë©”íƒ€ë°ì´í„° ìƒì„±] {md_filename}")


def save_to_csv(items: List[Dict], filename: str):
    """
    ë³‘ì› ìƒì„¸ì •ë³´ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë©”íƒ€ë°ì´í„° ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
    
    Parameters:
    -----------
    items : list
        ë³‘ì› ìƒì„¸ì •ë³´ ë¦¬ìŠ¤íŠ¸
    filename : str
        ì €ì¥í•  íŒŒì¼ëª… (ì˜ˆ: 'hospital_details.csv')
    """
    
    if not items:
        print("[ê²½ê³ ] ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df = pd.DataFrame(items)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬ (ì£¼ìš” ì»¬ëŸ¼ ìš°ì„ )
    priority_columns = [
        'ì›ë³¸_ê¸°ê´€ì½”ë“œ', 'ì›ë³¸_ë³‘ì›ëª…', 'ì›ë³¸_ì£¼ì†Œ',
        'yadmNm', 'addr', 'telno', 'hospUrl',
        'clCdNm', 'sidoCdNm', 'sgguCdNm', 'emdongNm',
        'postNo', 'XPos', 'YPos'
    ]
    
    # ì¡´ì¬í•˜ëŠ” ìš°ì„  ì»¬ëŸ¼ë§Œ ì„ íƒ
    existing_priority = [col for col in priority_columns if col in df.columns]
    # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼
    other_columns = [col for col in df.columns if col not in existing_priority]
    # ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ
    final_columns = existing_priority + other_columns
    df = df[final_columns]
    
    # CSV ì €ì¥ (UTF-8 BOM í¬í•¨, Excel í˜¸í™˜)
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"[ì €ì¥ ì™„ë£Œ] {filename} ({len(df)}ê±´)")
    print(f"  - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
    
    # ë©”íƒ€ë°ì´í„° ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
    generate_metadata_markdown(df, filename)


# ============================================================================
# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
# ============================================================================

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    print("="*80)
    print("ì˜ë£Œê¸°ê´€ë³„ìƒì„¸ì •ë³´ ì¡°íšŒ í”„ë¡œê·¸ë¨")
    print("="*80)
    print()
    
    # ========================================
    # 1. ì¸ì¦í‚¤ í™•ì¸
    # ========================================
    if SERVICE_KEY == "ì—¬ê¸°ì—_ë°œê¸‰ë°›ì€_ë””ì½”ë”©_ì¸ì¦í‚¤ë¥¼_ì…ë ¥í•˜ì„¸ìš”":
        print("[ì˜¤ë¥˜] ì¸ì¦í‚¤ë¥¼ ì„¤ì •í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì˜ SERVICE_KEY ë³€ìˆ˜ì— ë°œê¸‰ë°›ì€ ë””ì½”ë”© ì¸ì¦í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    
    # ========================================
    # 2. ì…ë ¥ íŒŒì¼ ì½ê¸°
    # ========================================
    try:
        hospital_df, detected_ykiho_column = load_hospital_list_from_csv(
            INPUT_CSV_FILE,
            ykiho_column=YKIHO_COLUMN
        )
        # ìë™ íƒì§€ëœ ì»¬ëŸ¼ëª… ì‚¬ìš©
        ykiho_column = detected_ykiho_column
    except Exception as e:
        print(f"[ì˜¤ë¥˜] CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        print()
        print("í•´ê²° ë°©ë²•:")
        print("1. INPUT_CSV_FILE ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("2. YKIHO_COLUMN ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("3. CSV íŒŒì¼ ì¸ì½”ë”©ì´ UTF-8ì¸ì§€ í™•ì¸")
        return
    
    # ========================================
    # 3. API í˜¸ì¶œ
    # ========================================
    try:
        # ëª¨ë“  ë³‘ì› ìƒì„¸ì •ë³´ ì¡°íšŒ
        details = get_all_hospital_details(
            service_key=SERVICE_KEY,
            use_encoded_key=USE_ENCODED_KEY,
            hospital_df=hospital_df,
            ykiho_column=ykiho_column
        )
        
        # ========================================
        # 4. CSV ì €ì¥
        # ========================================
        if details:
            # íŒŒì¼ëª… ìƒì„± (í˜„ì¬ ë‚ ì§œì‹œê°„ í¬í•¨)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            script_dir = Path(__file__).parent
            output_dir = script_dir / "data"
            output_dir.mkdir(exist_ok=True)
            filename = output_dir / f"ë³‘ì›ìƒì„¸ì •ë³´_{timestamp}.csv"
            
            save_to_csv(details, str(filename))
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜ ë°œìƒ] {e}")
        print()
        print("ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. ì¸ì¦í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸ (ë””ì½”ë”© í‚¤ ì‚¬ìš©)")
        print("2. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("3. API ì—”ë“œí¬ì¸íŠ¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("4. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ í›„ ì¬ì‹œë„")


# ============================================================================
# í”„ë¡œê·¸ë¨ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    main()
